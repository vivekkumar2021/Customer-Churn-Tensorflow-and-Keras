{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn - Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow: \n",
    "Tensorflow is a free and open-source library for machine learning and artificial intelligence. \n",
    "It was developed by Google. \n",
    "It can be used for developing large-scale machine learning applications.\n",
    "\n",
    "#### Keras:\n",
    "Keras is also an open-source library for machine learning and neural network but it higher-level API compared to Tensorflow and can run on top of Tensorflow.\n",
    "\n",
    "#### Note:\n",
    "Training of model and execution is fast in Tensorflow, while it is slow in Keras. Thus Keras is used mainly for rapid prototyping and applications dealing with small datasets. Whereas, Tensorflow is used for creating large-scale applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing libraries and checking for missing and duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataset rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#check missing values of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Checking unique values of the features to check if the dataset is imbalanced and drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check our target variable's unique values\n",
    "df[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above cell helps us to understand that this is a classical example of imbalanced dataset. \n",
    "#### 0 = Customers retained by the bank, 1 = Customers who left the bank\n",
    "\n",
    "#### Our concern is mainly on creating the model (not the best one, ofcourse) otherwise we would have considered the high imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inplace = True (To make permanent changes in the dataset)\n",
    "df.drop(columns = ['RowNumber', 'CustomerId', 'Surname'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are not doing EDA because we have already done it in our first part. We are only focsuing on building our model using Artificial Neural Network (ANN) with Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: One hot encoding categorical columns and Scaling all the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['Geography', 'Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have to scale all the values as few values have 6 digits and few only have 1 digit. \n",
    "#### This is also very useful while training Neural Networks as the value of the weights does not converge easily. \n",
    "#### So, we make sure that before builing a Neural Network model we scale the values beforehand.\n",
    "\n",
    "### Scaling all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns = ['Exited'])\n",
    "y = df['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000,), (2000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23082038, -0.94449979, -0.70174202, ...,  1.71490137,\n",
       "        -0.57273139,  0.91509065],\n",
       "       [-0.25150912, -0.94449979, -0.35520275, ..., -0.58312392,\n",
       "        -0.57273139, -1.09278791],\n",
       "       [-0.3963303 ,  0.77498705,  0.33787579, ...,  1.71490137,\n",
       "        -0.57273139, -1.09278791],\n",
       "       ...,\n",
       "       [ 0.22433188,  0.58393295,  1.3774936 , ..., -0.58312392,\n",
       "        -0.57273139, -1.09278791],\n",
       "       [ 0.13123255,  0.01077067,  1.03095433, ..., -0.58312392,\n",
       "        -0.57273139, -1.09278791],\n",
       "       [ 1.1656695 ,  0.29735181,  0.33787579, ...,  1.71490137,\n",
       "        -0.57273139,  0.91509065]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will see the transformed values in 2-D array.\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Time to use Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import tensorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential # There are 2 types of keras model: Sequential and Non-Sequential. We are focusing on sequential model now.\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add layers (adding weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='sigmoid', input_dim=11))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 1.0230\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.7570A: 0s - loss: 0.7\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6093\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5311\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4964\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4738\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4598A: 0s - loss: 0.45\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4541\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4493\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x258d892f4c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the stored locaion of weights and biases of our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02511641, -0.23492825, -0.04969935],\n",
       "        [-1.329942  ,  1.0450305 ,  1.1150635 ],\n",
       "        [ 0.04278281, -0.09251922, -0.15364797],\n",
       "        [-0.17936602,  0.10628829,  0.55420244],\n",
       "        [ 0.16912694, -0.29279986,  0.04958194],\n",
       "        [-0.07392672, -0.03482469, -0.2504669 ],\n",
       "        [ 1.1196731 , -0.49805674, -0.19117814],\n",
       "        [-0.09419082, -0.01518407,  0.2494997 ],\n",
       "        [-0.84143347,  0.40904197,  0.34730208],\n",
       "        [ 0.00245218, -0.07361576,  0.08043028],\n",
       "        [ 0.40243122, -0.3758122 , -0.6859438 ]], dtype=float32),\n",
       " array([ 1.2546271 , -0.64606047, -0.5300934 ], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch where the model weights and biases are stored\n",
    "\n",
    "#11x3 weights with 3 biases\n",
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.2322321 ],\n",
       "        [ 0.6156152 ],\n",
       "        [ 0.30836174]], dtype=float32),\n",
       " array([-0.9145755], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3x1 weights with 1 bias\n",
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14070347],\n",
       "       [0.16624165],\n",
       "       [0.1590567 ],\n",
       "       ...,\n",
       "       [0.11347693],\n",
       "       [0.17178965],\n",
       "       [0.32864255]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are getting the prediction not as 0 and 1 based on the dataset \n",
    "#because we are using sigmoid function whose output is between 0 and 1 which is a probability. \n",
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to decide the threshold by ourselves. \n",
    "#Here, we are taking the threshold as 0.5 but we should use ROC curve to find out the optimal threshold for our predictions.\n",
    "y_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up our threshold at 0.5\n",
    "y_pred = np.where(y_log > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluating model metrics and methods to enhance accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7925"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps to enhance accuracy score:\n",
    "\n",
    "#1. Increase the epochs to 100 or even 1000\n",
    "#2. Change activation function from \"sigmoid\" to \"ReLU\"\n",
    "#3. Increase the no of nodes of layer (Here, from 3 nodes to 10,30 etc., and from 1 to 3,5,etc.,)\n",
    "#Note: Keep eperimenting with the nodes and layers. If we increase the nodes and layers too much then it will cause overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Enhancing the model performance using the notes listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing hidden layers to 11 and adding an extra layer also both having activation function = relu\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(11, activation='relu', input_dim=11))\n",
    "model.add(Dense(11, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding accuracy also directly\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.5929 - accuracy: 0.7028 - val_loss: 0.4835 - val_accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8010 - val_loss: 0.4467 - val_accuracy: 0.8025\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8055 - val_loss: 0.4302 - val_accuracy: 0.8081\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8080 - val_loss: 0.4192 - val_accuracy: 0.8163\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8143 - val_loss: 0.4067 - val_accuracy: 0.8169\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8230 - val_loss: 0.3914 - val_accuracy: 0.8306\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8411 - val_loss: 0.3750 - val_accuracy: 0.8363\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8445 - val_loss: 0.3640 - val_accuracy: 0.8444\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8514 - val_loss: 0.3574 - val_accuracy: 0.8450\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8588 - val_loss: 0.3532 - val_accuracy: 0.8512\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8558 - val_loss: 0.3510 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8546 - val_loss: 0.3501 - val_accuracy: 0.8531\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8568 - val_loss: 0.3500 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8624 - val_loss: 0.3494 - val_accuracy: 0.8544\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8589 - val_loss: 0.3506 - val_accuracy: 0.8519\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8637 - val_loss: 0.3497 - val_accuracy: 0.8537\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3444 - accuracy: 0.8523 - val_loss: 0.3489 - val_accuracy: 0.8537\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8641 - val_loss: 0.3494 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8599 - val_loss: 0.3481 - val_accuracy: 0.8531\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8623 - val_loss: 0.3508 - val_accuracy: 0.8519\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8696 - val_loss: 0.3492 - val_accuracy: 0.8544\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8553 - val_loss: 0.3479 - val_accuracy: 0.8531\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8651 - val_loss: 0.3489 - val_accuracy: 0.8487\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8633 - val_loss: 0.3475 - val_accuracy: 0.8550\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8607 - val_loss: 0.3484 - val_accuracy: 0.8512\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8655 - val_loss: 0.3476 - val_accuracy: 0.8562\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8644 - val_loss: 0.3471 - val_accuracy: 0.8519\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8614 - val_loss: 0.3468 - val_accuracy: 0.8550\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8691 - val_loss: 0.3467 - val_accuracy: 0.8531\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8679 - val_loss: 0.3470 - val_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8696 - val_loss: 0.3470 - val_accuracy: 0.8506\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8665 - val_loss: 0.3477 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8679 - val_loss: 0.3456 - val_accuracy: 0.8519\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8716 - val_loss: 0.3462 - val_accuracy: 0.8506\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8650 - val_loss: 0.3456 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8592 - val_loss: 0.3449 - val_accuracy: 0.8494\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8716 - val_loss: 0.3477 - val_accuracy: 0.8469\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8665 - val_loss: 0.3452 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8716 - val_loss: 0.3456 - val_accuracy: 0.8494\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8681 - val_loss: 0.3446 - val_accuracy: 0.8519\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3257 - accuracy: 0.8672 - val_loss: 0.3448 - val_accuracy: 0.8487\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8603 - val_loss: 0.3462 - val_accuracy: 0.8475\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8661 - val_loss: 0.3445 - val_accuracy: 0.8512\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8722 - val_loss: 0.3444 - val_accuracy: 0.8506\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8588 - val_loss: 0.3457 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8611 - val_loss: 0.3447 - val_accuracy: 0.8506\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8638 - val_loss: 0.3453 - val_accuracy: 0.8512\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8632 - val_loss: 0.3464 - val_accuracy: 0.8469\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8669 - val_loss: 0.3438 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8686 - val_loss: 0.3457 - val_accuracy: 0.8537\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8698 - val_loss: 0.3459 - val_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8678 - val_loss: 0.3451 - val_accuracy: 0.8531\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8692 - val_loss: 0.3451 - val_accuracy: 0.8506\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8595 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8682 - val_loss: 0.3455 - val_accuracy: 0.8519\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8720 - val_loss: 0.3449 - val_accuracy: 0.8519\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8735 - val_loss: 0.3448 - val_accuracy: 0.8506\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8619 - val_loss: 0.3456 - val_accuracy: 0.8500\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8726 - val_loss: 0.3454 - val_accuracy: 0.8506\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8707 - val_loss: 0.3449 - val_accuracy: 0.8519\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8741 - val_loss: 0.3455 - val_accuracy: 0.8506\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8643 - val_loss: 0.3462 - val_accuracy: 0.8506\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8659 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8741 - val_loss: 0.3466 - val_accuracy: 0.8487\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8680 - val_loss: 0.3468 - val_accuracy: 0.8506\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8673 - val_loss: 0.3459 - val_accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8696 - val_loss: 0.3461 - val_accuracy: 0.8506\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8768 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8697 - val_loss: 0.3459 - val_accuracy: 0.8519\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8562 - val_loss: 0.3490 - val_accuracy: 0.8487\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8665 - val_loss: 0.3466 - val_accuracy: 0.8500\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8723 - val_loss: 0.3468 - val_accuracy: 0.8519\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8759 - val_loss: 0.3469 - val_accuracy: 0.8500\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8673 - val_loss: 0.3476 - val_accuracy: 0.8506\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8776 - val_loss: 0.3460 - val_accuracy: 0.8512\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8712 - val_loss: 0.3474 - val_accuracy: 0.8506\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8719 - val_loss: 0.3474 - val_accuracy: 0.8500\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8635 - val_loss: 0.3481 - val_accuracy: 0.8494\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8654 - val_loss: 0.3484 - val_accuracy: 0.8494\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8629 - val_loss: 0.3484 - val_accuracy: 0.8494\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8686 - val_loss: 0.3474 - val_accuracy: 0.8500\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8679 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8702 - val_loss: 0.3490 - val_accuracy: 0.8475\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.8575 - val_loss: 0.3482 - val_accuracy: 0.8500\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8621 - val_loss: 0.3481 - val_accuracy: 0.8512\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8642 - val_loss: 0.3494 - val_accuracy: 0.8481\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8679 - val_loss: 0.3490 - val_accuracy: 0.8519\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8644 - val_loss: 0.3503 - val_accuracy: 0.8475\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8660 - val_loss: 0.3492 - val_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8677 - val_loss: 0.3498 - val_accuracy: 0.8494\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8727 - val_loss: 0.3480 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8699 - val_loss: 0.3495 - val_accuracy: 0.8487\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8693 - val_loss: 0.3474 - val_accuracy: 0.8456\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8760 - val_loss: 0.3473 - val_accuracy: 0.8487\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8711 - val_loss: 0.3480 - val_accuracy: 0.8487\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8659 - val_loss: 0.3471 - val_accuracy: 0.8487\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8672 - val_loss: 0.3482 - val_accuracy: 0.8469\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8655 - val_loss: 0.3476 - val_accuracy: 0.8462\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8633 - val_loss: 0.3507 - val_accuracy: 0.8500\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8751 - val_loss: 0.3498 - val_accuracy: 0.8481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x258d9d18310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increase epochs to 100. Add valaidation_splits paramater. Here it's 0.2. \n",
    "#(Eg: Out of 8000 customers, our model will run on 8000 - 20% customers and \n",
    "#test it with the remaining 20% to give the accuracy. This is a very good standard to validate your model performance)\n",
    "\n",
    "#Note: Our end goal is to reduce the loss and increase the accuracy\n",
    "#IMP NOTE:Acuuracy of both training and validation set hsould increase gradually. \n",
    "#If only training accuracy is increasing and validation acuuracy is stagnant, then it is a case of overfitting\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional to get every layers weights\n",
    "\n",
    "#model.layers[0].get_weights()\n",
    "#model.layers[1].get_weights()\n",
    "#model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_log > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Plotting and checking loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8689 - val_loss: 0.3480 - val_accuracy: 0.8469\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8672 - val_loss: 0.3501 - val_accuracy: 0.8494\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8694 - val_loss: 0.3503 - val_accuracy: 0.8506\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8700 - val_loss: 0.3499 - val_accuracy: 0.8481\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8691 - val_loss: 0.3522 - val_accuracy: 0.8475\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8694 - val_loss: 0.3490 - val_accuracy: 0.8487\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3137 - accuracy: 0.8703 - val_loss: 0.3499 - val_accuracy: 0.8506\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.8695 - val_loss: 0.3497 - val_accuracy: 0.8481\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8716 - val_loss: 0.3491 - val_accuracy: 0.8481\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8695 - val_loss: 0.3504 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8694 - val_loss: 0.3504 - val_accuracy: 0.8475\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8687 - val_loss: 0.3493 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8706 - val_loss: 0.3486 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8700 - val_loss: 0.3499 - val_accuracy: 0.8494\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8708 - val_loss: 0.3491 - val_accuracy: 0.8512\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8703 - val_loss: 0.3505 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8691 - val_loss: 0.3498 - val_accuracy: 0.8481\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8705 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8694 - val_loss: 0.3504 - val_accuracy: 0.8487\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8683 - val_loss: 0.3495 - val_accuracy: 0.8487\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8695 - val_loss: 0.3505 - val_accuracy: 0.8481\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8706 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8723 - val_loss: 0.3516 - val_accuracy: 0.8481\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8700 - val_loss: 0.3530 - val_accuracy: 0.8469\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8684 - val_loss: 0.3516 - val_accuracy: 0.8494\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8706 - val_loss: 0.3500 - val_accuracy: 0.8475\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8708 - val_loss: 0.3496 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8695 - val_loss: 0.3498 - val_accuracy: 0.8481\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8700 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8695 - val_loss: 0.3487 - val_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8705 - val_loss: 0.3495 - val_accuracy: 0.8506\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8698 - val_loss: 0.3511 - val_accuracy: 0.8475\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8702 - val_loss: 0.3505 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8705 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8708 - val_loss: 0.3509 - val_accuracy: 0.8487\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8703 - val_loss: 0.3512 - val_accuracy: 0.8475\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8714 - val_loss: 0.3502 - val_accuracy: 0.8469\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8702 - val_loss: 0.3518 - val_accuracy: 0.8475\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8691 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8695 - val_loss: 0.3519 - val_accuracy: 0.8469\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8692 - val_loss: 0.3527 - val_accuracy: 0.8456\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8712 - val_loss: 0.3509 - val_accuracy: 0.8475\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8689 - val_loss: 0.3521 - val_accuracy: 0.8475\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8705 - val_loss: 0.3529 - val_accuracy: 0.8469\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8700 - val_loss: 0.3501 - val_accuracy: 0.8506\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8712 - val_loss: 0.3505 - val_accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8722 - val_loss: 0.3521 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8469\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3111 - accuracy: 0.8708 - val_loss: 0.3517 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8703 - val_loss: 0.3520 - val_accuracy: 0.8456\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8709 - val_loss: 0.3525 - val_accuracy: 0.8462\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8703 - val_loss: 0.3521 - val_accuracy: 0.8475\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3112 - accuracy: 0.8692 - val_loss: 0.3510 - val_accuracy: 0.8481\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.8714 - val_loss: 0.3523 - val_accuracy: 0.8462\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.8703 - val_loss: 0.3524 - val_accuracy: 0.8531\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.8708 - val_loss: 0.3564 - val_accuracy: 0.8456\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3112 - accuracy: 0.8706 - val_loss: 0.3522 - val_accuracy: 0.8469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3107 - accuracy: 0.8705 - val_loss: 0.3523 - val_accuracy: 0.8487\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3110 - accuracy: 0.8705 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8711 - val_loss: 0.3533 - val_accuracy: 0.8438\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8694 - val_loss: 0.3527 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.8714 - val_loss: 0.3521 - val_accuracy: 0.8456\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3103 - accuracy: 0.8716 - val_loss: 0.3535 - val_accuracy: 0.8475\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8711 - val_loss: 0.3505 - val_accuracy: 0.8512\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.8703 - val_loss: 0.3503 - val_accuracy: 0.8487\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3105 - accuracy: 0.8700 - val_loss: 0.3534 - val_accuracy: 0.8487\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8703 - val_loss: 0.3528 - val_accuracy: 0.8481\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3109 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8469\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8711 - val_loss: 0.3504 - val_accuracy: 0.8494\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3108 - accuracy: 0.8711 - val_loss: 0.3504 - val_accuracy: 0.8487\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3102 - accuracy: 0.8720 - val_loss: 0.3514 - val_accuracy: 0.8487\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8714 - val_loss: 0.3495 - val_accuracy: 0.8500\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3099 - accuracy: 0.8708 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3104 - accuracy: 0.8712 - val_loss: 0.3502 - val_accuracy: 0.8506\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3103 - accuracy: 0.8717 - val_loss: 0.3519 - val_accuracy: 0.8462\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.8722 - val_loss: 0.3522 - val_accuracy: 0.8481\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3099 - accuracy: 0.8725 - val_loss: 0.3531 - val_accuracy: 0.8506\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3103 - accuracy: 0.8711 - val_loss: 0.3504 - val_accuracy: 0.8487\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3104 - accuracy: 0.8711 - val_loss: 0.3506 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8723 - val_loss: 0.3505 - val_accuracy: 0.8487\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8708 - val_loss: 0.3499 - val_accuracy: 0.8506\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3093 - accuracy: 0.8722 - val_loss: 0.3514 - val_accuracy: 0.8475\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8711 - val_loss: 0.3525 - val_accuracy: 0.8469\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3092 - accuracy: 0.8719 - val_loss: 0.3516 - val_accuracy: 0.8506\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8725 - val_loss: 0.3502 - val_accuracy: 0.8494\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8730 - val_loss: 0.3520 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.8708 - val_loss: 0.3507 - val_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8730 - val_loss: 0.3507 - val_accuracy: 0.8525\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8720 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.8720 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3097 - accuracy: 0.8722 - val_loss: 0.3510 - val_accuracy: 0.8494\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.8712 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8719 - val_loss: 0.3545 - val_accuracy: 0.8487\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3087 - accuracy: 0.8714 - val_loss: 0.3512 - val_accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8728 - val_loss: 0.3498 - val_accuracy: 0.8519\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8731 - val_loss: 0.3524 - val_accuracy: 0.8512\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.8739 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.8723 - val_loss: 0.3516 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.8723 - val_loss: 0.3518 - val_accuracy: 0.8469\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.8700 - val_loss: 0.3525 - val_accuracy: 0.8494\n"
     ]
    }
   ],
   "source": [
    "#we can directly update the previous code. This is for demo purpose\n",
    "\n",
    "#creating history variable to store training and validation (of epochs) data\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3148421347141266,\n",
       "  0.31437408924102783,\n",
       "  0.3147590756416321,\n",
       "  0.3145278990268707,\n",
       "  0.31425756216049194,\n",
       "  0.31400153040885925,\n",
       "  0.3137073218822479,\n",
       "  0.31449344754219055,\n",
       "  0.31393226981163025,\n",
       "  0.3140878975391388,\n",
       "  0.3135818839073181,\n",
       "  0.31405362486839294,\n",
       "  0.3137297034263611,\n",
       "  0.314115971326828,\n",
       "  0.31314992904663086,\n",
       "  0.31297996640205383,\n",
       "  0.31332501769065857,\n",
       "  0.3134838342666626,\n",
       "  0.31307026743888855,\n",
       "  0.31327980756759644,\n",
       "  0.31338492035865784,\n",
       "  0.313152015209198,\n",
       "  0.3126699924468994,\n",
       "  0.31335023045539856,\n",
       "  0.3124223053455353,\n",
       "  0.3128776550292969,\n",
       "  0.3122543394565582,\n",
       "  0.31266331672668457,\n",
       "  0.31213995814323425,\n",
       "  0.31216737627983093,\n",
       "  0.3126731216907501,\n",
       "  0.31234458088874817,\n",
       "  0.31195127964019775,\n",
       "  0.31227120757102966,\n",
       "  0.31184452772140503,\n",
       "  0.31190094351768494,\n",
       "  0.3117547035217285,\n",
       "  0.31196969747543335,\n",
       "  0.3121492266654968,\n",
       "  0.3120066821575165,\n",
       "  0.3120296001434326,\n",
       "  0.3114636540412903,\n",
       "  0.311776727437973,\n",
       "  0.3115342855453491,\n",
       "  0.3113473355770111,\n",
       "  0.3114830553531647,\n",
       "  0.31106215715408325,\n",
       "  0.31149613857269287,\n",
       "  0.31114718317985535,\n",
       "  0.3117733299732208,\n",
       "  0.3117065131664276,\n",
       "  0.3116134703159332,\n",
       "  0.31124624609947205,\n",
       "  0.3111933171749115,\n",
       "  0.3106001913547516,\n",
       "  0.31078270077705383,\n",
       "  0.3112298548221588,\n",
       "  0.31074368953704834,\n",
       "  0.31104838848114014,\n",
       "  0.3103571832180023,\n",
       "  0.31096306443214417,\n",
       "  0.31081318855285645,\n",
       "  0.3102830946445465,\n",
       "  0.31049424409866333,\n",
       "  0.31055140495300293,\n",
       "  0.3105490505695343,\n",
       "  0.310537189245224,\n",
       "  0.31087520718574524,\n",
       "  0.31029099225997925,\n",
       "  0.3107987344264984,\n",
       "  0.3101755380630493,\n",
       "  0.3099135160446167,\n",
       "  0.30985376238822937,\n",
       "  0.3104057013988495,\n",
       "  0.31033802032470703,\n",
       "  0.30984652042388916,\n",
       "  0.30994758009910583,\n",
       "  0.3103179335594177,\n",
       "  0.31040158867836,\n",
       "  0.30960121750831604,\n",
       "  0.30994194746017456,\n",
       "  0.309304803609848,\n",
       "  0.31049200892448425,\n",
       "  0.30915623903274536,\n",
       "  0.30961698293685913,\n",
       "  0.308904230594635,\n",
       "  0.3094632029533386,\n",
       "  0.3089074194431305,\n",
       "  0.30961355566978455,\n",
       "  0.3092321753501892,\n",
       "  0.3096988797187805,\n",
       "  0.30905869603157043,\n",
       "  0.308768630027771,\n",
       "  0.3086518943309784,\n",
       "  0.30881252884864807,\n",
       "  0.3088574707508087,\n",
       "  0.30816683173179626,\n",
       "  0.30869242548942566,\n",
       "  0.30849194526672363,\n",
       "  0.3088219463825226],\n",
       " 'accuracy': [0.8689062595367432,\n",
       "  0.8671875,\n",
       "  0.8693749904632568,\n",
       "  0.8700000047683716,\n",
       "  0.8690624833106995,\n",
       "  0.8693749904632568,\n",
       "  0.870312511920929,\n",
       "  0.8695312738418579,\n",
       "  0.8715624809265137,\n",
       "  0.8695312738418579,\n",
       "  0.8693749904632568,\n",
       "  0.8687499761581421,\n",
       "  0.8706250190734863,\n",
       "  0.8700000047683716,\n",
       "  0.8707812428474426,\n",
       "  0.870312511920929,\n",
       "  0.8690624833106995,\n",
       "  0.8704687356948853,\n",
       "  0.8693749904632568,\n",
       "  0.8682812452316284,\n",
       "  0.8695312738418579,\n",
       "  0.8706250190734863,\n",
       "  0.8723437786102295,\n",
       "  0.8700000047683716,\n",
       "  0.8684375286102295,\n",
       "  0.8706250190734863,\n",
       "  0.8707812428474426,\n",
       "  0.8695312738418579,\n",
       "  0.8700000047683716,\n",
       "  0.8695312738418579,\n",
       "  0.8704687356948853,\n",
       "  0.8698437213897705,\n",
       "  0.8701562285423279,\n",
       "  0.8704687356948853,\n",
       "  0.8707812428474426,\n",
       "  0.870312511920929,\n",
       "  0.8714062571525574,\n",
       "  0.8701562285423279,\n",
       "  0.8690624833106995,\n",
       "  0.8695312738418579,\n",
       "  0.8692187666893005,\n",
       "  0.8712499737739563,\n",
       "  0.8689062595367432,\n",
       "  0.8704687356948853,\n",
       "  0.8700000047683716,\n",
       "  0.8712499737739563,\n",
       "  0.8721874952316284,\n",
       "  0.8704687356948853,\n",
       "  0.8707812428474426,\n",
       "  0.870312511920929,\n",
       "  0.8709375262260437,\n",
       "  0.870312511920929,\n",
       "  0.8692187666893005,\n",
       "  0.8714062571525574,\n",
       "  0.870312511920929,\n",
       "  0.8707812428474426,\n",
       "  0.8706250190734863,\n",
       "  0.8704687356948853,\n",
       "  0.8704687356948853,\n",
       "  0.87109375,\n",
       "  0.8693749904632568,\n",
       "  0.8714062571525574,\n",
       "  0.8715624809265137,\n",
       "  0.87109375,\n",
       "  0.870312511920929,\n",
       "  0.8700000047683716,\n",
       "  0.870312511920929,\n",
       "  0.8704687356948853,\n",
       "  0.87109375,\n",
       "  0.87109375,\n",
       "  0.8720312714576721,\n",
       "  0.8714062571525574,\n",
       "  0.8707812428474426,\n",
       "  0.8712499737739563,\n",
       "  0.8717187643051147,\n",
       "  0.8721874952316284,\n",
       "  0.8725000023841858,\n",
       "  0.87109375,\n",
       "  0.87109375,\n",
       "  0.8723437786102295,\n",
       "  0.8707812428474426,\n",
       "  0.8721874952316284,\n",
       "  0.87109375,\n",
       "  0.871874988079071,\n",
       "  0.8725000023841858,\n",
       "  0.8729687333106995,\n",
       "  0.8707812428474426,\n",
       "  0.8729687333106995,\n",
       "  0.8720312714576721,\n",
       "  0.8720312714576721,\n",
       "  0.8721874952316284,\n",
       "  0.8712499737739563,\n",
       "  0.871874988079071,\n",
       "  0.8714062571525574,\n",
       "  0.8728125095367432,\n",
       "  0.8731250166893005,\n",
       "  0.8739062547683716,\n",
       "  0.8723437786102295,\n",
       "  0.8723437786102295,\n",
       "  0.8700000047683716],\n",
       " 'val_loss': [0.3480292856693268,\n",
       "  0.35013678669929504,\n",
       "  0.3502711057662964,\n",
       "  0.3499071002006531,\n",
       "  0.3522460162639618,\n",
       "  0.3489651381969452,\n",
       "  0.3498547375202179,\n",
       "  0.3496696352958679,\n",
       "  0.3491206467151642,\n",
       "  0.35041946172714233,\n",
       "  0.35040873289108276,\n",
       "  0.34930041432380676,\n",
       "  0.3486279249191284,\n",
       "  0.34989017248153687,\n",
       "  0.34911179542541504,\n",
       "  0.35052379965782166,\n",
       "  0.34978795051574707,\n",
       "  0.3513725996017456,\n",
       "  0.35044264793395996,\n",
       "  0.3495279550552368,\n",
       "  0.3505004048347473,\n",
       "  0.35098397731781006,\n",
       "  0.35155460238456726,\n",
       "  0.35300618410110474,\n",
       "  0.35161659121513367,\n",
       "  0.35001593828201294,\n",
       "  0.3495602309703827,\n",
       "  0.3498431146144867,\n",
       "  0.3509734869003296,\n",
       "  0.3487113118171692,\n",
       "  0.3495345413684845,\n",
       "  0.3510986268520355,\n",
       "  0.3504739999771118,\n",
       "  0.35096466541290283,\n",
       "  0.35086292028427124,\n",
       "  0.35119903087615967,\n",
       "  0.3502042293548584,\n",
       "  0.3517599105834961,\n",
       "  0.3513146638870239,\n",
       "  0.3519457280635834,\n",
       "  0.3526623547077179,\n",
       "  0.3509254455566406,\n",
       "  0.35211431980133057,\n",
       "  0.35289955139160156,\n",
       "  0.35008516907691956,\n",
       "  0.3505193293094635,\n",
       "  0.35206863284111023,\n",
       "  0.35212138295173645,\n",
       "  0.35173743963241577,\n",
       "  0.3519936501979828,\n",
       "  0.35247546434402466,\n",
       "  0.35207808017730713,\n",
       "  0.35098063945770264,\n",
       "  0.35228800773620605,\n",
       "  0.35237789154052734,\n",
       "  0.3564300835132599,\n",
       "  0.35218650102615356,\n",
       "  0.352299302816391,\n",
       "  0.3514105975627899,\n",
       "  0.3532578945159912,\n",
       "  0.3526507616043091,\n",
       "  0.3520672619342804,\n",
       "  0.35345780849456787,\n",
       "  0.35050827264785767,\n",
       "  0.3503240644931793,\n",
       "  0.35338181257247925,\n",
       "  0.3527902662754059,\n",
       "  0.3521192967891693,\n",
       "  0.35044413805007935,\n",
       "  0.3503757119178772,\n",
       "  0.3514290153980255,\n",
       "  0.34952789545059204,\n",
       "  0.3512924909591675,\n",
       "  0.35017433762550354,\n",
       "  0.35192054510116577,\n",
       "  0.35215649008750916,\n",
       "  0.35310569405555725,\n",
       "  0.35040393471717834,\n",
       "  0.35055068135261536,\n",
       "  0.35054928064346313,\n",
       "  0.3498747944831848,\n",
       "  0.35138583183288574,\n",
       "  0.35251399874687195,\n",
       "  0.35158005356788635,\n",
       "  0.3502201437950134,\n",
       "  0.35199084877967834,\n",
       "  0.350668340921402,\n",
       "  0.3507182002067566,\n",
       "  0.35118815302848816,\n",
       "  0.35129380226135254,\n",
       "  0.3510083258152008,\n",
       "  0.35127466917037964,\n",
       "  0.3544510304927826,\n",
       "  0.35122475028038025,\n",
       "  0.34980273246765137,\n",
       "  0.3523825705051422,\n",
       "  0.35142242908477783,\n",
       "  0.35155585408210754,\n",
       "  0.3518271744251251,\n",
       "  0.35254889726638794],\n",
       " 'val_accuracy': [0.846875011920929,\n",
       "  0.8493750095367432,\n",
       "  0.8506249785423279,\n",
       "  0.8481249809265137,\n",
       "  0.8475000262260437,\n",
       "  0.8487499952316284,\n",
       "  0.8506249785423279,\n",
       "  0.8481249809265137,\n",
       "  0.8481249809265137,\n",
       "  0.8518750071525574,\n",
       "  0.8475000262260437,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8493750095367432,\n",
       "  0.8512499928474426,\n",
       "  0.8462499976158142,\n",
       "  0.8481249809265137,\n",
       "  0.8500000238418579,\n",
       "  0.8487499952316284,\n",
       "  0.8487499952316284,\n",
       "  0.8481249809265137,\n",
       "  0.8475000262260437,\n",
       "  0.8481249809265137,\n",
       "  0.846875011920929,\n",
       "  0.8493750095367432,\n",
       "  0.8475000262260437,\n",
       "  0.8462499976158142,\n",
       "  0.8481249809265137,\n",
       "  0.8475000262260437,\n",
       "  0.8525000214576721,\n",
       "  0.8506249785423279,\n",
       "  0.8475000262260437,\n",
       "  0.8500000238418579,\n",
       "  0.8475000262260437,\n",
       "  0.8487499952316284,\n",
       "  0.8475000262260437,\n",
       "  0.846875011920929,\n",
       "  0.8475000262260437,\n",
       "  0.8493750095367432,\n",
       "  0.846875011920929,\n",
       "  0.8456249833106995,\n",
       "  0.8475000262260437,\n",
       "  0.8475000262260437,\n",
       "  0.846875011920929,\n",
       "  0.8506249785423279,\n",
       "  0.8493750095367432,\n",
       "  0.8462499976158142,\n",
       "  0.846875011920929,\n",
       "  0.8450000286102295,\n",
       "  0.8456249833106995,\n",
       "  0.8462499976158142,\n",
       "  0.8475000262260437,\n",
       "  0.8481249809265137,\n",
       "  0.8462499976158142,\n",
       "  0.8531249761581421,\n",
       "  0.8456249833106995,\n",
       "  0.846875011920929,\n",
       "  0.8487499952316284,\n",
       "  0.8462499976158142,\n",
       "  0.84375,\n",
       "  0.8462499976158142,\n",
       "  0.8456249833106995,\n",
       "  0.8475000262260437,\n",
       "  0.8512499928474426,\n",
       "  0.8487499952316284,\n",
       "  0.8487499952316284,\n",
       "  0.8481249809265137,\n",
       "  0.846875011920929,\n",
       "  0.8493750095367432,\n",
       "  0.8487499952316284,\n",
       "  0.8487499952316284,\n",
       "  0.8500000238418579,\n",
       "  0.8493750095367432,\n",
       "  0.8506249785423279,\n",
       "  0.8462499976158142,\n",
       "  0.8481249809265137,\n",
       "  0.8506249785423279,\n",
       "  0.8487499952316284,\n",
       "  0.8500000238418579,\n",
       "  0.8487499952316284,\n",
       "  0.8506249785423279,\n",
       "  0.8475000262260437,\n",
       "  0.846875011920929,\n",
       "  0.8506249785423279,\n",
       "  0.8493750095367432,\n",
       "  0.8500000238418579,\n",
       "  0.8525000214576721,\n",
       "  0.8525000214576721,\n",
       "  0.8525000214576721,\n",
       "  0.8493750095367432,\n",
       "  0.8493750095367432,\n",
       "  0.8475000262260437,\n",
       "  0.8487499952316284,\n",
       "  0.8500000238418579,\n",
       "  0.8518750071525574,\n",
       "  0.8512499928474426,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.846875011920929,\n",
       "  0.8493750095367432]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking loss, accuracy, val_loss and val_accuracy which are stored inside 'history' variable as dictionary format\n",
    "#(here, it is 100 values each for 100 epochs)\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting this confusing data into plot for better representation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x258dbc18940>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x258ddcfee80>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
